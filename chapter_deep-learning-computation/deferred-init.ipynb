{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following additional libraries are needed to run this\n",
    "notebook. Note that running on Colab is experimental, please report a Github\n",
    "issue if you have any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U mxnet-cu101==1.7.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 延后初始化\n",
    ":label:`sec_deferred_init`\n",
    "\n",
    "到目前为止，我们忽略了建立网络时需要做的以下这些事情：\n",
    "\n",
    "* 我们定义了网络架构，但没有指定输入维度。\n",
    "* 我们添加层时没有指定前一层的输出维度。\n",
    "* 我们在初始化参数时，甚至没有足够的信息来确定模型应该包含多少参数。\n",
    "\n",
    "你可能会对我们的代码能运行感到惊讶。\n",
    "毕竟，深度学习框架无法判断网络的输入维度是什么。\n",
    "这里的诀窍是框架的*延后初始化*（defers initialization），\n",
    "即直到数据第一次通过模型传递时，框架才会动态地推断出每个层的大小。\n",
    "\n",
    "在以后，当使用卷积神经网络时，\n",
    "由于输入维度（即图像的分辨率）将影响每个后续层的维数，\n",
    "有了该技术将更加方便。\n",
    "现在我们在编写代码时无须知道维度是什么就可以设置参数，\n",
    "这种能力可以大大简化定义和修改模型的任务。\n",
    "接下来，我们将更深入地研究初始化机制。\n",
    "\n",
    "## 实例化网络\n",
    "\n",
    "首先，让我们实例化一个多层感知机。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 1,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [],
   "source": [
    "from mxnet import np, npx\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add(nn.Dense(256, activation='relu'))\n",
    "    net.add(nn.Dense(10))\n",
    "    return net\n",
    "\n",
    "net = get_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "此时，因为输入维数是未知的，所以网络不可能知道输入层权重的维数。\n",
    "因此，框架尚未初始化任何参数，我们通过尝试访问以下参数进行确认。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 4,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Block.collect_params of Sequential(\n",
      "  (0): Dense(-1 -> 256, Activation(relu))\n",
      "  (1): Dense(-1 -> 10, linear)\n",
      ")>\n",
      "sequential0_ (\n",
      "  Parameter dense0_weight (shape=(256, -1), dtype=float32)\n",
      "  Parameter dense0_bias (shape=(256,), dtype=float32)\n",
      "  Parameter dense1_weight (shape=(10, -1), dtype=float32)\n",
      "  Parameter dense1_bias (shape=(10,), dtype=float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net.collect_params)\n",
    "print(net.collect_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "mxnet"
    ]
   },
   "source": [
    "注意，当参数对象存在时，每个层的输入维度为-1。\n",
    "MXNet使用特殊值-1表示参数维度仍然未知。\n",
    "此时，尝试访问`net[0].weight.data()`将触发运行时错误，\n",
    "提示必须先初始化网络，然后才能访问参数。\n",
    "现在让我们看看当我们试图通过`initialize`函数初始化参数时会发生什么。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter dense0_weight (shape=(256, -1), dtype=float32)\n",
       "  Parameter dense0_bias (shape=(256,), dtype=float32)\n",
       "  Parameter dense1_weight (shape=(10, -1), dtype=float32)\n",
       "  Parameter dense1_bias (shape=(10,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "mxnet"
    ]
   },
   "source": [
    "如我们所见，一切都没有改变。\n",
    "当输入维度未知时，调用`initialize`不会真正初始化参数。\n",
    "而是会在MXNet内部声明希望初始化参数，并且可以选择初始化分布。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "接下来让我们将数据通过网络，最终使框架初始化参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 11,
    "tab": [
     "mxnet"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential0_ (\n",
       "  Parameter dense0_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense0_bias (shape=(256,), dtype=float32)\n",
       "  Parameter dense1_weight (shape=(10, 256), dtype=float32)\n",
       "  Parameter dense1_bias (shape=(10,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.uniform(size=(2, 20))\n",
    "net(X)\n",
    "\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "一旦我们知道输入维数是20，框架可以通过代入值20来识别第一层权重矩阵的形状。\n",
    "识别出第一层的形状后，框架处理第二层，依此类推，直到所有形状都已知为止。\n",
    "注意，在这种情况下，只有第一层需要延迟初始化，但是框架仍是按顺序初始化的。\n",
    "等到知道了所有的参数形状，框架就可以初始化参数。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 延后初始化使框架能够自动推断参数形状，使修改模型架构变得容易，避免了一些常见的错误。\n",
    "* 我们可以通过模型传递数据，使框架最终初始化参数。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 如果你指定了第一层的输入尺寸，但没有指定后续层的尺寸，会发生什么？是否立即进行初始化？\n",
    "1. 如果指定了不匹配的维度会发生什么？\n",
    "1. 如果输入具有不同的维度，你需要做什么？提示：查看参数绑定的相关内容。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "mxnet"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/5770)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}